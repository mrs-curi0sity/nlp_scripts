{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset is glove 6B 50T\n",
    "# udemy nlp with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euclidean distance\n",
    "def dist1(a,b):\n",
    "    return np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine distance\n",
    "def dist2(a,b):\n",
    "    return 1-a.dot(b)/(np.linalg.norm(a)*np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    2\n",
      "dtype: int64\n",
      "euclidian distance 1.0\n",
      "cosine distance 0.05131670194948623\n"
     ]
    }
   ],
   "source": [
    "a = pd.Series([1,1])\n",
    "b = pd.Series([1,2])\n",
    "print(a)\n",
    "print(b)\n",
    "print(f'euclidian distance {dist1(a,b)}')\n",
    "print(f'cosine distance {dist2(a,b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2\n",
      "1    2\n",
      "dtype: int64\n",
      "0    2\n",
      "1    4\n",
      "dtype: int64\n",
      "euclidian distance 2.0\n",
      "cosine distance 0.05131670194948623\n"
     ]
    }
   ],
   "source": [
    "# the cosine distance does not change when doubeling\n",
    "# cosine distance only takes into account angel (the smaller the higher the similarity. )\n",
    "# euclidian looks at absolute length\n",
    "a_double = a*2\n",
    "b_double = b*2\n",
    "print(a_double)\n",
    "print(b_double)\n",
    "print(f'euclidian distance {dist1(a_double,b_double)}')\n",
    "print(f'cosine distance {dist2(a_double,b_double)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, metric = dist2, 'cosine'\n",
    "#alternative: dist, metric = dist1, 'euclidean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained word vectors\n",
    "def load_word2vec(path = '../large_files/glove.6B/glove.6B.50d.txt'):\n",
    "    print(f'loading word embeddings word to vec from path {path}')\n",
    "    \n",
    "    word2vec = {}\n",
    "    embedding = []\n",
    "    index_to_word = []\n",
    "    \n",
    "    with open(path) as file:\n",
    "        num = 0\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            \n",
    "            word = values[0]\n",
    "            vec = np.asarray(values[1:], dtype='float32')\n",
    "            \n",
    "            word2vec[word] = vec\n",
    "            \n",
    "            embedding.append(vec)\n",
    "            index_to_word.append(word)\n",
    "            \n",
    "            num +=1\n",
    "            if num % 200000 == 0:\n",
    "                print(f'line number {num}')\n",
    "                print(line)\n",
    "    \n",
    "    embedding = pd.DataFrame(embedding, index=word2vec.keys())\n",
    "    num_words, num_dims = embedding.shape\n",
    "    \n",
    "    print(f'total number of entries found:  {num_words}. Dimension: {num_dims}')\n",
    "    return(word2vec, embedding, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# king - man = X - woman\n",
    "# <=> X = woman - man + king\n",
    "# I wanted to solve this on my own, but it does not converge\n",
    "def find_analogies_lena(word1, word2, word3, embedding):\n",
    "    \n",
    "    for word in [word1, word2, word3]:\n",
    "        if word.lower() not in embedding.index:\n",
    "            print(f'sorry, I do not have an embedding for {word}')\n",
    "            return ''\n",
    "        \n",
    "    king = embedding.loc[word1.lower()]\n",
    "    man = embedding.loc[word2.lower()]\n",
    "    woman = embedding.loc[word3.lower()]\n",
    "    searched_vector = woman - man + king\n",
    "    \n",
    "    print(king, man, woman, searched_vector)\n",
    "    \n",
    "    #jetzt brauche ich eine Matrix, die mir die distanz searched_vector - word gibt\n",
    "    #pd_distances = pd.DataFrame(columns = embedding.index)\n",
    "    \n",
    "    #takes several minutes\n",
    "    #for word in embedding.index:\n",
    "    #    pd_distances[word] = dist1(searched_vector, embedding.loc[word])\n",
    "    \n",
    "    #print('And the searched vector is: ', searched_vector)\n",
    "    \n",
    "    print('computing distances')   \n",
    "    columns = embedding.index\n",
    "    embedding['Dist_to_word'] = embedding.apply(lambda row: dist1(searched_vector, row[columns]), axis=1)    \n",
    "    \n",
    "    print(embedding.head())\n",
    "    \n",
    "    print(pd_distances.loc[0:10, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_analogies(w1, w2, w3, D, index_to_word):\n",
    "  for w in (w1, w2, w3):\n",
    "    if w not in word2vec:\n",
    "      print(\"%s not in dictionary\" % w)\n",
    "      return\n",
    "\n",
    "  king = word2vec[w1]\n",
    "  man = word2vec[w2]\n",
    "  woman = word2vec[w3]\n",
    "  v0 = king - man + woman\n",
    "\n",
    "  distances = pairwise_distances(v0.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "  idxs = distances.argsort()[:4]\n",
    "  for idx in idxs:\n",
    "    word = index_to_word[idx]\n",
    "    if word not in (w1, w2, w3): \n",
    "      best_word = word\n",
    "      break\n",
    "\n",
    "  print(w1, \"-\", w2, \"=\", best_word, \"-\", w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbors(w,index_to_word, word2vec, D,  n=5 ):\n",
    "  if w not in word2vec:\n",
    "    print(\"%s not in dictionary:\" % w)\n",
    "    return\n",
    "\n",
    "  v = word2vec[w]\n",
    "  distances = pairwise_distances(v.reshape(1, D), embedding, metric=metric).reshape(V)\n",
    "  idxs = distances.argsort()[1:n+1]\n",
    "  print(\"neighbors of: %s\" % w)\n",
    "  for idx in idxs:\n",
    "    print(\"\\t%s\" % index_to_word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = '../large_files/glove.6B/glove.6B.50d.txt'\n",
    "\n",
    "#takes about 10 sec\n",
    "word2vec, embedding, index_to_word = load_word2vec(glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.418</td>\n",
       "      <td>0.24968</td>\n",
       "      <td>-0.41242</td>\n",
       "      <td>0.1217</td>\n",
       "      <td>0.34527</td>\n",
       "      <td>-0.044457</td>\n",
       "      <td>-0.49688</td>\n",
       "      <td>-0.17862</td>\n",
       "      <td>-0.00066</td>\n",
       "      <td>-0.6566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29871</td>\n",
       "      <td>-0.15749</td>\n",
       "      <td>-0.34758</td>\n",
       "      <td>-0.045637</td>\n",
       "      <td>-0.44251</td>\n",
       "      <td>0.18785</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.18411</td>\n",
       "      <td>-0.11514</td>\n",
       "      <td>-0.78581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0        1        2       3        4         5        6        7   \\\n",
       "the  0.418  0.24968 -0.41242  0.1217  0.34527 -0.044457 -0.49688 -0.17862   \n",
       "\n",
       "          8       9    ...          40       41       42        43       44  \\\n",
       "the -0.00066 -0.6566   ...    -0.29871 -0.15749 -0.34758 -0.045637 -0.44251   \n",
       "\n",
       "          45        46       47       48       49  \n",
       "the  0.18785  0.002785 -0.18411 -0.11514 -0.78581  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V, D = embedding.shape\n",
    "print(embedding.shape)\n",
    "embedding.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motivation - man = satisfaction - woman\n",
      "king - man = queen - woman\n",
      "france - paris = britain - london\n",
      "france - paris = italy - rome\n",
      "paris - france = rome - italy\n",
      "december - november = july - june\n",
      "miami - florida = houston - texas\n",
      "einstein - scientist = matisse - painter\n",
      "china - rice = chinese - bread\n",
      "man - woman = he - she\n",
      "man - woman = uncle - aunt\n",
      "man - woman = brother - sister\n",
      "man - woman = friend - wife\n",
      "man - woman = brother - friend\n",
      "man - woman = actor - actress\n",
      "man - woman = father - mother\n",
      "heir - heiress = queen - princess\n",
      "february - january = october - november\n"
     ]
    }
   ],
   "source": [
    "word1 = 'motivation'\n",
    "word2 = 'man'\n",
    "word3 = 'woman'\n",
    "#find_analogies_Lena(embedding, word1, word2, word3) # this is slow AF\n",
    "find_analogies(word1, word2, word3, D, index_to_word)\n",
    "find_analogies('king', 'man', 'woman',  D, index_to_word)\n",
    "find_analogies('france', 'paris', 'london',  D, index_to_word)\n",
    "find_analogies('france', 'paris', 'rome',  D, index_to_word)\n",
    "find_analogies('paris', 'france', 'italy',  D, index_to_word)\n",
    "find_analogies('december', 'november', 'june',  D, index_to_word)\n",
    "find_analogies('miami', 'florida', 'texas',  D, index_to_word)\n",
    "find_analogies('einstein', 'scientist', 'painter',  D, index_to_word)\n",
    "find_analogies('china', 'rice', 'bread',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'she',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'aunt',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'sister',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'wife',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'friend',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'actress',  D, index_to_word)\n",
    "find_analogies('man', 'woman', 'mother',  D, index_to_word)\n",
    "find_analogies('heir', 'heiress', 'princess',  D, index_to_word)\n",
    "find_analogies('february', 'january', 'november',  D, index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors of: king\n",
      "\tprince\n",
      "\tqueen\n",
      "\tii\n",
      "\temperor\n",
      "\tson\n",
      "neighbors of: france\n",
      "\tfrench\n",
      "\tbelgium\n",
      "\tparis\n",
      "\tspain\n",
      "\tnetherlands\n",
      "neighbors of: japan\n",
      "\tjapanese\n",
      "\tchina\n",
      "\tkorea\n",
      "\ttokyo\n",
      "\ttaiwan\n",
      "neighbors of: einstein\n",
      "\trelativity\n",
      "\tbohr\n",
      "\tphysics\n",
      "\theisenberg\n",
      "\tfreud\n",
      "neighbors of: woman\n",
      "\tgirl\n",
      "\tman\n",
      "\tmother\n",
      "\ther\n",
      "\tboy\n",
      "neighbors of: man\n",
      "\twoman\n",
      "\tboy\n",
      "\tanother\n",
      "\told\n",
      "\tone\n",
      "neighbors of: nephew\n",
      "\tcousin\n",
      "\tbrother\n",
      "\tgrandson\n",
      "\tson\n",
      "\tuncle\n",
      "neighbors of: february\n",
      "\toctober\n",
      "\tdecember\n",
      "\tjanuary\n",
      "\taugust\n",
      "\tseptember\n",
      "neighbors of: success\n",
      "\tachieved\n",
      "\tsuccessful\n",
      "\tever\n",
      "\tthanks\n",
      "\tbest\n",
      "neighbors of: money\n",
      "\tcash\n",
      "\tpaying\n",
      "\tfunds\n",
      "\tpay\n",
      "\traise\n",
      "neighbors of: love\n",
      "\tdream\n",
      "\tlife\n",
      "\tdreams\n",
      "\tloves\n",
      "\tme\n"
     ]
    }
   ],
   "source": [
    "nearest_neighbors('king',index_to_word, word2vec, D)\n",
    "nearest_neighbors('france',index_to_word, word2vec, D)\n",
    "nearest_neighbors('japan',index_to_word, word2vec, D)\n",
    "nearest_neighbors('einstein',index_to_word, word2vec, D)\n",
    "nearest_neighbors('woman',index_to_word, word2vec, D)\n",
    "nearest_neighbors('man',index_to_word, word2vec, D)\n",
    "nearest_neighbors('nephew',index_to_word, word2vec, D)\n",
    "nearest_neighbors('february',index_to_word, word2vec, D)\n",
    "nearest_neighbors('success',index_to_word, word2vec, D)\n",
    "nearest_neighbors('money',index_to_word, word2vec, D)\n",
    "nearest_neighbors('love',index_to_word, word2vec, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
